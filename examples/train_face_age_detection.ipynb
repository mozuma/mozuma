{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train an age detection model based on ArcFace features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a target=\"_blank\" href=\"https://github.com/mozuma/mozuma/blob/master/docs/examples/train_face_age_detection.ipynb\">\n",
    "  <img src=\"https://img.shields.io/static/v1?label=&message=See%20the%20source%20code&color=blue&logo=github&labelColor=black\" alt=\"See the source code\"/>\n",
    "</a>\n",
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/mozuma/mozuma/blob/master/docs/examples/train_face_age_detection.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>\n",
    "\n",
    "Import `mozuma` modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mozuma.models.arcface.pretrained import torch_arcface_insightface\n",
    "from mozuma.models.mtcnn.pretrained import torch_mtcnn\n",
    "from mozuma.torch.options import TorchRunnerOptions\n",
    "from mozuma.torch.runners import TorchInferenceRunner\n",
    "from mozuma.models.classification import LinearClassifierTorchModule\n",
    "from mozuma.torch.datasets import TorchTrainingDataset\n",
    "from mozuma.torch.runners import TorchTrainingRunner\n",
    "from mozuma.torch.options import TorchTrainingOptions\n",
    "from mozuma.torch.options import TorchRunnerOptions\n",
    "from mozuma.labels.base import LabelSet\n",
    "from mozuma.callbacks.memory import (\n",
    "    CollectBoundingBoxesInMemory,\n",
    "    CollectFeaturesInMemory,\n",
    "    CollectLabelsInMemory,\n",
    ")\n",
    "from mozuma.torch.datasets import (\n",
    "    ImageBoundingBoxDataset,\n",
    "    ListDataset,\n",
    "    LocalBinaryFilesDataset,\n",
    "    ImageDataset,\n",
    ")\n",
    "from mozuma.helpers.files import list_files_in_dir\n",
    "\n",
    "from ignite.metrics import Precision, Recall, Loss, Accuracy\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enable logging inside notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import sys\n",
    "\n",
    "logging.basicConfig(\n",
    "    format=\"%(asctime)s | %(levelname)s : %(message)s\",\n",
    "    level=logging.INFO,\n",
    "    stream=sys.stdout,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First download `UTKFace_inthewild` dataset from https://drive.google.com/drive/folders/1HROmgviy4jUUUaCdvvrQ8PcqtNg2jn3G\n",
    "Download and extract the 3 parts and place the folder `UTKFace_inthewild` in your home directory.\n",
    "part1 will serve as training set, while part2 will be our test set and part3 our valid set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_utkface = os.path.join(os.environ[\"HOME\"], \"UTKFace_inthewild\")\n",
    "train_filenames = list_files_in_dir(\n",
    "    os.path.join(path_to_utkface, \"part1\"), allowed_extensions=(\"jpg\",)\n",
    ")\n",
    "test_filenames = list_files_in_dir(\n",
    "    os.path.join(path_to_utkface, \"part2\"), allowed_extensions=(\"jpg\",)\n",
    ")\n",
    "valid_filenames = list_files_in_dir(\n",
    "    os.path.join(path_to_utkface, \"part3\"), allowed_extensions=(\"jpg\",)\n",
    ")\n",
    "train_dataset = ImageDataset(LocalBinaryFilesDataset(train_filenames))\n",
    "test_dataset = ImageDataset(LocalBinaryFilesDataset(test_filenames))\n",
    "valid_dataset = ImageDataset(LocalBinaryFilesDataset(valid_filenames))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract pretrained ArcFace features for all images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_device = \"cuda\"\n",
    "face_detector = torch_mtcnn(device=torch_device)\n",
    "face_extractor = torch_arcface_insightface(device=torch_device)\n",
    "\n",
    "\n",
    "def get_face_features(dset):\n",
    "    # Callbacks\n",
    "    bb = CollectBoundingBoxesInMemory()\n",
    "    ff = CollectFeaturesInMemory()\n",
    "\n",
    "    # Face detection runner\n",
    "    runner = TorchInferenceRunner(\n",
    "        model=face_detector,\n",
    "        dataset=dset,\n",
    "        callbacks=[bb],\n",
    "        options=TorchRunnerOptions(\n",
    "            data_loader_options={\"batch_size\": 1},\n",
    "            device=torch_device,\n",
    "            tqdm_enabled=True,\n",
    "        ),\n",
    "    )\n",
    "    runner.run()\n",
    "\n",
    "    # Dataset with detected faces\n",
    "    dataset = ImageBoundingBoxDataset(\n",
    "        image_dataset=ImageDataset(LocalBinaryFilesDataset(bb.indices)),\n",
    "        bounding_boxes=bb.bounding_boxes,\n",
    "    )\n",
    "\n",
    "    # Face extraction runner\n",
    "    runner = TorchInferenceRunner(\n",
    "        model=face_extractor,\n",
    "        dataset=dataset,\n",
    "        callbacks=[ff],\n",
    "        options=TorchRunnerOptions(\n",
    "            data_loader_options={\"batch_size\": 32},\n",
    "            device=torch_device,\n",
    "            tqdm_enabled=True,\n",
    "        ),\n",
    "    )\n",
    "    runner.run()\n",
    "\n",
    "    return bb, ff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_bb, train_ff = get_face_features(train_dataset)\n",
    "test_bb, test_ff = get_face_features(test_dataset)\n",
    "valid_bb, valid_ff = get_face_features(valid_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discretising the age into six categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "childhood = {i: \"childhood\" for i in range(0, 8)}\n",
    "puberty = {i: \"puberty\" for i in range(8, 13)}\n",
    "adolescence = {i: \"adolescence\" for i in range(13, 18)}\n",
    "adulthood = {i: \"adulthood\" for i in range(18, 35)}\n",
    "middle_age = {i: \"middle_age\" for i in range(35, 50)}\n",
    "seniority = {i: \"seniority\" for i in range(50, 120)}\n",
    "age2label = {\n",
    "    **childhood,\n",
    "    **puberty,\n",
    "    **adolescence,\n",
    "    **adulthood,\n",
    "    **middle_age,\n",
    "    **seniority,\n",
    "}\n",
    "\n",
    "\n",
    "def discretize_age(filenames):\n",
    "    labels = {}\n",
    "    for img_path in filenames:\n",
    "        m = re.search(\"(\\d+)_.*[.jpg]\", img_path)\n",
    "        if m:\n",
    "            age = int(m.group(1))\n",
    "            labels[img_path] = age2label[age]\n",
    "        else:\n",
    "            print(f\"{img_path} failed\")\n",
    "    assert len(labels) == len(filenames)\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = discretize_age(train_filenames)\n",
    "test_labels = discretize_age(test_filenames)\n",
    "valid_labels = discretize_age(valid_filenames)\n",
    "\n",
    "label_set = LabelSet(\n",
    "    label_set_unique_id=\"age\",\n",
    "    label_list=[\n",
    "        \"childhood\",\n",
    "        \"puberty\",\n",
    "        \"adolescence\",\n",
    "        \"adulthood\",\n",
    "        \"middle_age\",\n",
    "        \"seniority\",\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define train and validation set for training the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define train set\n",
    "train_dset = TorchTrainingDataset(\n",
    "    dataset=ListDataset(train_ff.features),\n",
    "    targets=label_set.get_label_ids(\n",
    "        [train_labels[img_path] for img_path, _ in train_ff.indices]\n",
    "    ),\n",
    ")\n",
    "# define valid set\n",
    "valid_dset = TorchTrainingDataset(\n",
    "    dataset=ListDataset(valid_ff.features),\n",
    "    targets=label_set.get_label_ids(\n",
    "        [valid_labels[img_path] for img_path, _ in valid_ff.indices]\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a linear classifier on top of the extracted features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_classifier = LinearClassifierTorchModule(\n",
    "    in_features=train_ff.features.shape[1], label_set=label_set\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training runner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = Precision(average=False)\n",
    "recall = Recall(average=False)\n",
    "F1 = (precision * recall * 2 / (precision + recall)).mean()\n",
    "\n",
    "loss_fn = F.cross_entropy\n",
    "trainer = TorchTrainingRunner(\n",
    "    model=age_classifier,\n",
    "    dataset=(train_dset, valid_dset),\n",
    "    callbacks=[],\n",
    "    options=TorchTrainingOptions(\n",
    "        data_loader_options={\"batch_size\": 32},\n",
    "        criterion=loss_fn,\n",
    "        optimizer=optim.Adam(age_classifier.parameters(), lr=1e-3),\n",
    "        metrics={\n",
    "            \"pre\": precision,\n",
    "            \"recall\": recall,\n",
    "            \"f1\": F1,\n",
    "            \"acc\": Accuracy(),\n",
    "            \"ce_loss\": Loss(loss_fn),\n",
    "        },\n",
    "        validate_every=1,\n",
    "        num_epoch=3,\n",
    "        tqdm_enabled=True,\n",
    "    ),\n",
    ")\n",
    "trainer.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get predictions on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callbacks\n",
    "score_test = CollectLabelsInMemory()\n",
    "\n",
    "# Do the predictions\n",
    "runner = TorchInferenceRunner(\n",
    "    model=age_classifier,\n",
    "    dataset=ListDataset(test_ff.features),\n",
    "    callbacks=[score_test],\n",
    "    options=TorchRunnerOptions(\n",
    "        data_loader_options={\"batch_size\": 32}, device=torch_device, tqdm_enabled=True\n",
    "    ),\n",
    ")\n",
    "runner.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ff_labels = [test_labels[img_path] for img_path, _ in test_ff.indices]\n",
    "print(classification_report(test_ff_labels, score_test.labels))"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,md"
  },
  "kernelspec": {
   "display_name": "Python 3.7.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "446fa4ae14fc0db07deeb22d284bdd26ac4d0fa6060970ce5f4cfd209622d30f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
